{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "109d171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class DDClient:\n",
    "    def __init__(self, debug=False):\n",
    "        self.api_key = os.getenv(\"DD_API_KEY\")\n",
    "        self.app_key = os.getenv(\"DD_APP_KEY\")\n",
    "        self.site = os.getenv(\"DD_SITE\", \"datadoghq.com\")\n",
    "        self.base = f\"https://api.{self.site}\"\n",
    "        self.debug = debug\n",
    "        self.headers = {\n",
    "            \"DD-API-KEY\": self.api_key,\n",
    "            \"DD-APPLICATION-KEY\": self.app_key,\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "\n",
    "    def query_metric(self, query: str, since: int, until: int) -> pd.DataFrame:\n",
    "        \"\"\"Fetch Datadog metrics as a DataFrame\"\"\"\n",
    "\n",
    "        params = {\"query\": query, \"from\": since, \"to\": until}\n",
    "        if self.debug:\n",
    "            print(f\"Querying {query} from {since} to {until}\")\n",
    "\n",
    "        url = f\"{self.base}/api/v1/query\"\n",
    "        resp = requests.get(url, headers=self.headers, params=params)\n",
    "        if resp.status_code != 200:\n",
    "            raise Exception(f\"Error: {resp.status_code} - {resp.text}\")\n",
    "        \n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "        return self._metric_to_dataframe(data)\n",
    "\n",
    "    def _metric_to_dataframe(self, data: dict) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Convert Datadog time-series JSON response to a clean pandas DataFrame.\n",
    "        \"\"\"\n",
    "        if \"series\" not in data or not data[\"series\"]:\n",
    "            print(\"No series data found in response.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        rows = []\n",
    "        for series in data[\"series\"]:\n",
    "            metric = series.get(\"metric\", \"\")\n",
    "            scope = series.get(\"scope\", \"\")\n",
    "            host = None\n",
    "\n",
    "            # Extract host tag if available\n",
    "            for tag in series.get(\"tag_set\", []):\n",
    "                if tag.startswith(\"host:\"):\n",
    "                    host = tag.split(\":\", 1)[1]\n",
    "\n",
    "            for point in series.get(\"pointlist\", []):\n",
    "                if point[1] is not None:  # skip nulls\n",
    "                    timestamp = point[0]\n",
    "                    value = point[1]\n",
    "                    rows.append(\n",
    "                        {\n",
    "                            \"timestamp\": pd.to_datetime(timestamp, unit=\"ms\"),\n",
    "                            \"value\": value,\n",
    "                            \"metric\": metric,\n",
    "                            \"host\": host,\n",
    "                            \"scope\": scope,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        df = pd.DataFrame(rows)\n",
    "        if not df.empty:\n",
    "            df = df.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "        return df\n",
    "\n",
    "    \n",
    "    def query_logs(self, since: int, until: int, query: str = \"*\", limit=1000):\n",
    "        \"\"\"Query Datadog logs within a time range and return as a pandas DataFrame.\"\"\"\n",
    "\n",
    "        url = f\"{self.base}/api/v2/logs/events/search\"\n",
    "        payload = {\n",
    "            \"filter\": {\n",
    "                \"from\": f\"{since}\",\n",
    "                \"to\": f\"{until}\",\n",
    "                \"query\": query,\n",
    "            },\n",
    "            \"page\": {\"limit\": limit},\n",
    "            \"sort\": \"desc\",\n",
    "        }\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"Querying logs with query='{query}' from {since} to {until}\")\n",
    "\n",
    "        resp = requests.post(url, headers=self.headers, json=payload)\n",
    "        if resp.status_code != 200:\n",
    "            raise Exception(f\"Error: {resp.status_code} - {resp.text}\")\n",
    "\n",
    "        data = resp.json()\n",
    "        return self._logs_to_dataframe(data)\n",
    "\n",
    "    def _logs_to_dataframe(self, data: dict) -> pd.DataFrame:\n",
    "        \"\"\"Convert Datadog logs JSON to pandas DataFrame.\"\"\"\n",
    "        if not data or \"data\" not in data:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        rows = []\n",
    "        for item in data[\"data\"]:\n",
    "            attrs = item.get(\"attributes\", {})\n",
    "            ts = attrs.get(\"timestamp\")\n",
    "            msg = attrs.get(\"message\", \"\")\n",
    "            host = attrs.get(\"host\", None)\n",
    "            service = attrs.get(\"service\", None)\n",
    "            status = attrs.get(\"status\", None)\n",
    "\n",
    "            rows.append({\n",
    "                \"timestamp\": pd.to_datetime(ts),\n",
    "                \"message\": msg,\n",
    "                \"host\": host,\n",
    "                \"service\": service,\n",
    "                \"status\": status,\n",
    "            })\n",
    "\n",
    "        df = pd.DataFrame(rows)\n",
    "        return df.sort_values(\"timestamp\").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f3c606f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            timestamp      value           metric       host           scope\n",
      "0 2025-10-14 18:24:00   8.020758  system.cpu.user  DZ_Laptop  host:DZ_Laptop\n",
      "1 2025-10-14 18:24:20   8.750083  system.cpu.user  DZ_Laptop  host:DZ_Laptop\n",
      "2 2025-10-14 18:24:40   7.291630  system.cpu.user  DZ_Laptop  host:DZ_Laptop\n",
      "3 2025-10-14 18:25:00  10.331986  system.cpu.user  DZ_Laptop  host:DZ_Laptop\n",
      "4 2025-10-14 18:25:20   6.301845  system.cpu.user  DZ_Laptop  host:DZ_Laptop\n"
     ]
    }
   ],
   "source": [
    "dd = DDClient()\n",
    "now = int(time.time())\n",
    "hour_ago = now - 3600\n",
    "\n",
    "df_metrics = dd.query_metric(query=\"avg:system.cpu.user{*} by {host}\", since=hour_ago, until=now)\n",
    "print(df_metrics.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02044d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         timestamp                              message  \\\n",
      "0 2025-10-14 18:26:02.660000+00:00  10/14/2025 14:26:02 INFO Test log 0   \n",
      "1 2025-10-14 18:26:04.676000+00:00  10/14/2025 14:26:04 INFO Test log 1   \n",
      "2 2025-10-14 18:26:06.697000+00:00  10/14/2025 14:26:06 INFO Test log 2   \n",
      "3 2025-10-14 18:26:08.719000+00:00  10/14/2025 14:26:08 INFO Test log 3   \n",
      "4 2025-10-14 18:26:10.745000+00:00  10/14/2025 14:26:10 INFO Test log 4   \n",
      "\n",
      "        host   service status  \n",
      "0  DZ_Laptop  localapp   info  \n",
      "1  DZ_Laptop  localapp   info  \n",
      "2  DZ_Laptop  localapp   info  \n",
      "3  DZ_Laptop  localapp   info  \n",
      "4  DZ_Laptop  localapp   info  \n",
      "Returned 10 logs\n"
     ]
    }
   ],
   "source": [
    "logs_df = dd.query_logs(since=hour_ago, until=now)\n",
    "print(logs_df.head())\n",
    "print(f\"Returned {len(logs_df)} logs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
